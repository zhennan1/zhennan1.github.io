---
layout: archive
title: "CV"
permalink: /cv/
author_profile: true
redirect_from:
  - /resume
---

{% include base_path %}

**Education**

<!-- * Ph.D in Version Control Theory, GitHub University, 2018 (expected) -->
<!-- * M.S. in Jekyll, GitHub University, 2014 -->
* **Master of Engineering in Electronic Information (Computer Science and Technology), Tsinghua University, 2028 (expected)**
  * Advisor: Associate Professor [Jianfei Chen](https://ml.cs.tsinghua.edu.cn/~jianfei/)
  * Research Lab: [TSAIL](https://ml.cs.tsinghua.edu.cn/)
* **Bachelor of Engineering in Computer Science and Technology, Tsinghua University, 2026 (expected)**
  * Major GPA: 3.76/4.0
  * Relevant Coursework (Grade: A): Ordinary Differential Equations; Probability and Statistics; Fundamentals of Programming; Programing and Training; Software Engineering; Operating Systems; Principles of Signal Processing; Database Special Topic Training
  * Previous Major: Medicine. Pivoted to Computer Science to pursue a passion for Artificial Intelligence.

**Research Statement**

* My research focuses on improving the long context capability of large language models (LLMs).

**Publications**

* **Scaling External Knowledge Input Beyond Context Windows of LLMs via Multi-Agent Collaboration**  
  Zijun Liu\*, **Zhennan Wan\***, Peng Li, Ming Yan, Ji Zhang, Fei Huang, Yang Liu  
  *arXiv 2025*. Under review. [[Paper](https://arxiv.org/abs/2505.21471)] [[GitHub](https://github.com/THUNLP-MT/ExtAgents)] [[Data](https://huggingface.co/datasets/zhennan1/ExtAgents)]  
  \*Equal contribution.

**Research Experience**

* **September 2024 - May 2025: Natural Language Processing Lab, Tsinghua University (THUNLP)**
  * Advisor: Associate Professor [Peng Li](https://lpeng.net/) and Professor [Yang Liu](https://nlp.csai.tsinghua.edu.cn/~ly/)
  * Research Topic: Scaling External Knowledge Input Beyond the Context Length of LLMs via Multi-Agent Collaboration
  * Role: Co-leader
  * Description: Developed a multi-agent framework, ExtAgents, to overcome the context window limitations of current large language models (LLMs) and enable better scalability in inference-time knowledge integration without longer-context training.

* **February 2024 - August 2024: 3D Visual Computing and Machine Intelligence (3DVICI) Lab, Institute for Interdisciplinary Information Sciences (IIIS), Tsinghua University**
  * Advisor: Assistant Professor [Li Yi](https://ericyi.github.io/)
  * Research Topic: Editing Human Videos for Robotic Skill Training
  * Role: Co-leader
  * Description: Utilized video editing techniques to convert human hand-object interaction videos into robotic hand-object interaction videos; extracted 6D poses of human videos; compared human data with robot data, referencing pipelines such as OpenVLA, to validate the effectiveness of human videos for robotic training.

* **July 2023 - August 2023: State Key Laboratory of Intelligent Technology and Systems, Department of Computer Science and Technology, Tsinghua University**
  * Advisor: Assistant Professor [Bin Fang](https://scholar.google.com/citations?user=5G47IcIAAAAJ&hl=zh-CN)
  * Research Topic: Human-Machine Collaborative Operation of Super-functional Prosthetic Hands
  * Role: Project Member
  * Description: Trained neural network models to extract human hand movements from electromyographic signals of the human arm.

**Internship Experience**

* **June 2025 - August 2025: Code Intelligence Center, Technology and Engineering Group (TEG), Tencent**
  * Project Topic: Applying CodeLLMs for Multi-Point Code Completion and Smart Rewriting
  * Role: Student Leader
  * Description: Researched data synthesis algorithms for CodeLLMs on cursor prediction and intelligent rewrite tasks; trained a CodeLLM-based fusion model to implement cursor prediction and intelligent rewrite suggestions during code editing. Our group was ranked 1st among 5 groups.

**Course Project**

* **April 2025 - June 2025: Frontiers in AI safety and Governance (2025 Spring)**
  * Lecturer: Professor [Peng Cui](https://pengcui.thumedialab.com/)
  * Project Topic: Adaptive Safety Priming: Inference-Time Safeguards for Large Reasoning Models
  * Role: Independent
  * Description: Developed a lightweight and dynamic safety mechanism, Adaptive Safety Priming (ASP), for large reasoning models (LRM) at inference time, which leverages their step-by-step inference process to enable real-time intervention. This approach provides a more adaptive and resource efficient path to develop robustly safe models. [Report](https://github.com/zhennan1/ASP/blob/main/Report.pdf)

<!-- * Spring 2024: Academic Pages Collaborator
  * GitHub University
  * Duties includes: Updates and improvements to template
  * Supervisor: The Users

* Fall 2015: Research Assistant
  * GitHub University
  * Duties included: Merging pull requests
  * Supervisor: Professor Hub

* Summer 2015: Research Assistant
  * GitHub University
  * Duties included: Tagging issues
  * Supervisor: Professor Git -->
  
**Skills**

* Programming
  * C/C++, Python, Pytorch
* Tools
  * Git, Linux, Django, Docker, LaTeX
* Language
  * College English Test-6 (CET6): 601 / 710 (top 10% of the normative group)

**Awards**

* Tsinghua University Software Engineering Outstanding Project Award (2024)

<!-- Publications
======
  <ul>{% for post in site.publications reversed %}
    {% include archive-single-cv.html %}
  {% endfor %}</ul>
  
Talks
======
  <ul>{% for post in site.talks reversed %}
    {% include archive-single-talk-cv.html  %}
  {% endfor %}</ul>
  
Teaching
======
  <ul>{% for post in site.teaching reversed %}
    {% include archive-single-cv.html %}
  {% endfor %}</ul>
  
Service and leadership
======
* Currently signed in to 43 different slack teams -->
